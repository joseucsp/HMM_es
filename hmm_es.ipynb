{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM for Named Entity Recognition in Spanish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "f = open(\"data/esp-train.txt\", \"r\", encoding='utf8',errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text  = f.read()\n",
    "train_lines = train_text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines :  273038\n"
     ]
    }
   ],
   "source": [
    "n_lines = len(train_lines)\n",
    "print(\"Lines : \", n_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(lines):\n",
    "    input_ = []\n",
    "    label_ = []\n",
    "    blanks = 0\n",
    "    \n",
    "    n_lines = len(lines)\n",
    "    \n",
    "    for i in range(n_lines):\n",
    "        if lines[i] != \"\":\n",
    "            Xi, yi = lines[i].split(\" \")\n",
    "            input_.append(Xi)\n",
    "            label_.append(yi)\n",
    "        else:\n",
    "            blanks+=1\n",
    "        \n",
    "    n_lines -= blanks\n",
    "    \n",
    "    return input_, label_, n_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, label_train, n_lines = getData(train_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (n_lines == len(input_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "label_count =  collections.Counter(label_train)\n",
    "label_prob  = { k : v/n_lines for k, v in label_count.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (1 == sum(label_prob.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to map X to y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_function(input_train, label_input,n_lines, prob_y):\n",
    "    res = {}\n",
    "    \n",
    "    for i in range(n_lines):\n",
    "        if input_train[i] not in res:\n",
    "            res[input_train[i]] = {}\n",
    "        \n",
    "        if label_input[i] not in res[input_train[i]]:\n",
    "                res[input_train[i]][label_input[i]]  = 1\n",
    "                \n",
    "        else:\n",
    "            res[input_train[i]][label_input[i]] += 1 \n",
    "    \n",
    "    \n",
    "    for key, val in res.items():\n",
    "        sumLabels = sum(val.values())\n",
    "        for k, v in val.items():\n",
    "            res[key][k] = v / sumLabels\n",
    "    \n",
    "    for key, val in res.items():\n",
    "        for k, v in val.items():\n",
    "            res[key][k] = v * prob_y[k]\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dist = mapping_function(input_train, label_train, n_lines, label_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to predict labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(word, prob_dist):\n",
    "    if word in prob_dist:\n",
    "        maxVal = max(prob_dist[word].values())\n",
    "        for k, v in prob_dist[word].items():\n",
    "            if v == maxVal:\n",
    "                return k\n",
    "    else:\n",
    "        return '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B-LOC'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('Australia', prob_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting accuracy for 'esp-texta.txt' and 'esp-textb.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(input_test, label_test, prob_dist):\n",
    "    n   = len(input_test)\n",
    "    acc = 0.\n",
    "    \n",
    "    for i in range(n):\n",
    "        if predict(input_test[i], prob_dist) == label_test[i]:\n",
    "            acc += 1\n",
    "            \n",
    "    return acc/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/esp-testa.txt\", \"r\", encoding='utf8',errors=\"ignore\")\n",
    "\n",
    "testa_text  = f.read()\n",
    "testa_lines = testa_text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_testa, label_testa, n_lines = getData(testa_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 'esp-testa.txt' : 0.867\n"
     ]
    }
   ],
   "source": [
    "acc_a = testing(input_testa, label_testa, prob_dist)\n",
    "print(\"Accuracy for 'esp-testa.txt' : {:4.3f}\".format(acc_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/esp-testb.txt\", \"r\", encoding='utf8',errors=\"ignore\")\n",
    "\n",
    "testb_text  = f.read()\n",
    "testb_lines = testb_text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_testb, label_testb, n_lines = getData(testb_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 'esp-testb.txt' : 0.897\n"
     ]
    }
   ],
   "source": [
    "acc_b = testing(input_testb, label_testb, prob_dist)\n",
    "print(\"Accuracy for 'esp-testb.txt' : {:4.3f}\".format(acc_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
